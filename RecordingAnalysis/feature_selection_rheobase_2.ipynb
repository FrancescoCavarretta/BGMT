{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import copy\n",
    "import json\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron information for its identification\n",
    "neuron_id_info = ['date', 'slice id', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_early_recordings(grp_data):\n",
    "    '''\n",
    "        For each group, keep only the earliest recording\n",
    "    '''\n",
    "    ret_data = pd.DataFrame()\n",
    "    for _, g in grp_data:\n",
    "        g.sort_values('time stamp', inplace=True)\n",
    "        ret_data = ret_data.append( g.iloc[0, :] )\n",
    "    return ret_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset with measures of firing properties\n",
    "data = pd.read_csv(\"preprocessed_data_efeatures.csv\")\n",
    "data = data.merge(pd.read_csv('data_selection.csv')[neuron_id_info].drop_duplicates(), on=neuron_id_info, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current amplitude round off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_current(row):\n",
    "    inc = {'fi':20.0, 'rmih':50.0, 'tburst':50.0}[row['protocol']]\n",
    "    return round(row['step current']/inc)*inc\n",
    "\n",
    "\n",
    "# round off for current amplitudes\n",
    "#data['step current'] = data.apply(round_current, axis=1)\n",
    "#data['bias current'] = data['bias current'].apply( lambda x : round(x/10.0)*10.0 )\n",
    "#data['total current'] = data['total current'].apply( lambda x : round(x/20.0)*20.0 )\n",
    "\n",
    "data['total current'] = data['step current'] + data['bias current']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. F-I curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only traces selected\n",
    "data_fi = data.merge(pd.read_csv('data_selection.csv')[['filename', 'file key']], on=['filename', 'file key'], how='inner')\n",
    "\n",
    "# keep early recordings only\n",
    "data_fi = get_early_recordings(data_fi.groupby(neuron_id_info + ['step current']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking(data, increments=np.arange(1, 300, 1), nstep=3, apthresh=4, hyper=False, perc_round=5):\n",
    "    \n",
    "    # if we deliver hyperpolarizing current check rebound spikes\n",
    "    ap_count_attr = 'AP_count_after_stim' if hyper else 'AP_count'\n",
    "    \n",
    "    data = data[neuron_id_info + ['step current', ap_count_attr]]\n",
    "    \n",
    "    # remove traces with less than 4 spikes\n",
    "    data.drop(data[data[ap_count_attr] < apthresh].index, inplace=True)\n",
    "\n",
    "    rank = pd.DataFrame()\n",
    "    df_by_step = pd.DataFrame()\n",
    "    for cur_inc in increments:\n",
    "        _data = pd.DataFrame()\n",
    "        \n",
    "        # get the fi curve for each neuron\n",
    "        for k, g in data.groupby(neuron_id_info):\n",
    "            if hyper:\n",
    "                cur0 = g['step current'].max() # threshold current\n",
    "            else:\n",
    "                cur0 = g['step current'].min() # threshold current\n",
    "                \n",
    "            # get normalized step current\n",
    "            g['step current norm'] = g['step current'].apply(lambda x: round(100 * x / cur0 / perc_round) * perc_round)\n",
    "\n",
    "            if g['step current norm'].nunique() < g.shape[0]:\n",
    "                print (\"Warning! Colliding current steps.\")\n",
    "                print(g['step current norm'].nunique(), g.shape[0], cur0)\n",
    "            \n",
    "            # get the 3 steps\n",
    "            __data = pd.DataFrame()\n",
    "            if nstep > 1:\n",
    "                for i in range(nstep):\n",
    "                    __data = pd.concat([__data, g[g['step current norm'] == (100 + i * cur_inc)]])     \n",
    "            else:\n",
    "                __data = pd.concat([__data, g[g['step current norm'] == (100 + cur_inc)]])      \n",
    "            \n",
    "\n",
    "            # if it does not have all the steps do not add\n",
    "            if __data.shape[0] < nstep:\n",
    "                continue\n",
    "            elif __data.shape[0] > nstep:\n",
    "                print('Warning: there are too many traces')\n",
    "                \n",
    "            __data['cur step'] = cur_inc\n",
    "                \n",
    "            # add the new data\n",
    "            _data = pd.concat([_data, __data])\n",
    "        \n",
    "        if _data.shape[0] > 0:\n",
    "            df_by_step = pd.concat([df_by_step, _data])\n",
    "\n",
    "            # analyze by type\n",
    "            for x in _data['state'].unique():\n",
    "                _rows_sel = _data[_data['state'] == x]\n",
    "                sz = _rows_sel.shape[0] \n",
    "\n",
    "                row = {}\n",
    "                row['n'] = sz\n",
    "                row['state'] = x\n",
    "\n",
    "                row['cur step'] = cur_inc\n",
    "                rank = rank.append(row, ignore_index=True)                    \n",
    "\n",
    "    return rank, df_by_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6ohda\n",
      "     n  state  cur step\n",
      "2    3  6ohda        10\n",
      "9    3  6ohda        30\n",
      "16   3  6ohda        60\n",
      "20   3  6ohda        80\n",
      "28   3  6ohda       175\n",
      "31   3  6ohda       250\n",
      "10   6  6ohda        35\n",
      "12   6  6ohda        40\n",
      "24   6  6ohda       125\n",
      "25   6  6ohda       150\n",
      "29   6  6ohda       200\n",
      "5    9  6ohda        20\n",
      "7    9  6ohda        25\n",
      "18   9  6ohda        75\n",
      "13  15  6ohda        50\n",
      "21  15  6ohda       100\n",
      "\n",
      "control\n",
      "     n    state  cur step\n",
      "0    3  control         5\n",
      "17   3  control        75\n",
      "23   3  control       125\n",
      "26   3  control       150\n",
      "30   3  control       200\n",
      "3    6  control        15\n",
      "19   6  control        80\n",
      "27   6  control       175\n",
      "6    9  control        25\n",
      "14   9  control        50\n",
      "15   9  control        60\n",
      "8   12  control        30\n",
      "11  12  control        40\n",
      "22  12  control       100\n",
      "1   21  control        10\n",
      "4   24  control        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank, df_by_step = ranking(data_fi, nstep=3)    \n",
    "# remove current steps with fewer trials than 1 or no APs\n",
    "rank = rank[rank['n'] > 1]\n",
    "for k, g in rank.groupby('state'):\n",
    "    g = g.sort_values(by=['n', 'cur step'])\n",
    "    print (k)\n",
    "    print (g)\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_step = df_by_step[(df_by_step['cur step'] == 20) & (df_by_step['state'] == 'control') | (df_by_step['cur step'] == 100) & (df_by_step['state'] == '6ohda')] # select steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data\n",
    "cols = neuron_id_info + ['step current'] # columns\n",
    "\n",
    "# select fi data\n",
    "data_fi_selection = data_fi[data_fi[cols].isin(df_by_step[cols]).all(axis=1)]\n",
    "\n",
    "# get normalized step current\n",
    "for k, r in data_fi_selection.iterrows():\n",
    "    # get position in the df\n",
    "    pos = (r[cols] == df_by_step[cols]).all(axis=1)\n",
    "    \n",
    "    # set current norm\n",
    "    data_fi_selection.loc[k, ['step current norm']] = df_by_step.loc[pos, ['step current norm']].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 37)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fi_selection.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sag amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the trace selection\n",
    "data_sag = data[data['protocol'] == 'rmih']\n",
    "\n",
    "# get round step current\n",
    "data_sag['step current round'] = data_sag.apply(round_current, axis=1)\n",
    "\n",
    "# neuron filtering\n",
    "data_sag = data_sag.merge(data_fi_selection[neuron_id_info].drop_duplicates(), on=neuron_id_info, how='inner')\n",
    "\n",
    "# keep early recordings only\n",
    "data_sag = get_early_recordings(data_sag.groupby(neuron_id_info + ['step current round', 'stim dur']))\n",
    "\n",
    "# keep only 0 to negative\n",
    "data_sag = data_sag[data_sag['step current'] <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6ohda\n",
      "   n  state  cur step\n",
      "8  3  6ohda       295\n",
      "3  4  6ohda       100\n",
      "6  4  6ohda       200\n",
      "\n",
      "control\n",
      "   n    state  cur step\n",
      "9  2  control       295\n",
      "2  4  control        50\n",
      "4  6  control       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank, df_by_step = ranking(data_sag, nstep=1, apthresh=2, hyper=True, perc_round=5)    \n",
    "# remove current steps with fewer trials than 1 or no APs\n",
    "rank = rank[rank['n'] > 1]\n",
    "for k, g in rank.groupby('state'):\n",
    "    g = g.sort_values(by=['n', 'cur step'])\n",
    "    print (k)\n",
    "    print (g)\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_step = df_by_step[df_by_step['cur step'] == 100] # select steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data\n",
    "cols = neuron_id_info + ['step current'] # columns\n",
    "\n",
    "# select fi data\n",
    "data_sag_selection = data_sag[data_sag[cols].isin(df_by_step[cols]).all(axis=1)]\n",
    "\n",
    "# get normalized step current\n",
    "for k, r in data_sag_selection.iterrows():\n",
    "    # get position in the df\n",
    "    pos = (r[cols] == df_by_step[cols]).all(axis=1)\n",
    "    \n",
    "    # set current norm\n",
    "    data_sag_selection.loc[k, ['step current norm']] = df_by_step.loc[pos, ['step current norm']].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 38)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sag_selection.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## old featurs\n",
    "\n",
    "efeatures = {\n",
    "      'fi':[\n",
    "        'AP_amplitude',\n",
    "        'AHP_depth',\n",
    "        'AP_width',\n",
    "        'AP_count',\n",
    "        'time_to_first_spike',\n",
    "        'inv_first_ISI',\n",
    "        'inv_second_ISI',\n",
    "        'inv_last_ISI',\n",
    "        'adaptation_index2',\n",
    "        'voltage_base',\n",
    "        'voltage_after_stim',\n",
    "        'AP_count_before_stim',\n",
    "        'AP_count_after_stim',\n",
    "        'max_amp_difference',\n",
    "        'clustering_index',\n",
    "        'fast_AHP'\n",
    "      ],\n",
    "      'rmih':[\n",
    "        'voltage_base',\n",
    "        'AP1_amp_rev',\n",
    "        'AP2_amp_rev',\n",
    "        'time_to_first_spike',\n",
    "        'AP_count_before_stim',\n",
    "        'AP_count_after_stim',\n",
    "        'inv_first_ISI',\n",
    "        'inv_second_ISI',\n",
    "        'inv_last_ISI',\n",
    "        'voltage_after_stim',\n",
    "        'sag_amplitude',\n",
    "        'voltage_deflection',\n",
    "      ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_feature = {\n",
    "    'control':{},\n",
    "    '6ohda':{}\n",
    "}\n",
    "\n",
    "json_file_protocol = {\n",
    "    'control':{},\n",
    "    '6ohda':{}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_json(row, thresh=None):\n",
    "    ret = [ ]\n",
    "    for col_name in row.columns:\n",
    "        ret.append(\n",
    "            {\n",
    "                \"feature\":col_name, \n",
    "                \"val\":[row.loc['mean', col_name], row.loc['std', col_name]],\n",
    "                \"n\":row.loc['count', col_name],\n",
    "                \"weight\":1.0\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if thresh:\n",
    "            ret[-1].update({'threshold':thresh})\n",
    "    return { \"soma.v\":ret }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_json_output(data, efeature_names, cur_key, thresh=None, key_fmt='', stim_dur_flag=True, stim_amp_flag=True):\n",
    "    _key_fmt = key_fmt + 'Step'\n",
    "    if stim_amp_flag:\n",
    "        _key_fmt += '%i'\n",
    "    if stim_dur_flag:\n",
    "        _key_fmt += '_%ims'\n",
    "        \n",
    "    json_file_output = {}\n",
    "    for k, g in data.groupby('state'):\n",
    "        json_file_output[k] = {}\n",
    "        \n",
    "        output = {}\n",
    "        for kk, gg in g.groupby([cur_key, 'stim dur']):\n",
    "            gg_descr = gg[efeature_names].describe().loc[['count', 'mean', 'std'], :] \n",
    "\n",
    "            _kk = ()\n",
    "            \n",
    "            if stim_amp_flag:\n",
    "                _kk += (kk[0],)\n",
    "                \n",
    "            if stim_dur_flag:\n",
    "                _kk += (kk[1],)\n",
    "\n",
    "            output.update( {(_key_fmt % _kk):row_to_json(gg_descr, thresh=thresh)} )\n",
    "\n",
    "        json_file_output[k].update(output)\n",
    "    return json_file_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output = get_json_output(data_fi_selection, efeatures['fi'], 'step current norm', key_fmt='', thresh=-20)\n",
    "\n",
    "for k in json_file_feature:\n",
    "    json_file_feature[k].update(output[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_json_output(data_sag_selection, efeatures['rmih'], 'step current norm', key_fmt='Sag', thresh=-35)\n",
    "\n",
    "for k in json_file_feature:\n",
    "    json_file_feature[k].update(output[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the time constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_constants = {'6ohda':\n",
    "                  {\"Pulse\":{\"soma.v\":[{\"feature\":\"decay_time_constant_after_stim2\",\"val\":[21.04,13.2],\"weight\":1}]}},\n",
    "                   'control':\n",
    "                   {\"Pulse\":{\"soma.v\":[{\"feature\":\"decay_time_constant_after_stim2\",\"val\":[20.69,10.27],\"weight\":1}]}}\n",
    "                 }\n",
    "\n",
    "for k in json_file_feature.keys():\n",
    "    json_file_feature[k].update(time_constants[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_json_output(data_sag_selection, [ 'input_resistance' ], 'step current norm', stim_amp_flag=False)\n",
    "for k in json_file_feature:\n",
    "    json_file_feature[k].update(output[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP peaks/amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in json_file_feature.values():\n",
    "    for entry_name, entry in output.items():\n",
    "        for entry1 in entry['soma.v']:\n",
    "            if (entry1['feature'].startswith('AP_amplitude') or \\\n",
    "                entry1['feature'].startswith('AP1_peak') or \\\n",
    "                entry1['feature'].startswith('AP2_peak') or \\\n",
    "                entry1['feature'].startswith('AP1_amp') or \\\n",
    "                entry1['feature'].startswith('AP2_amp')):\n",
    "                entry1['weight'] = 1\n",
    "            elif entry1['feature'] == 'AP_count_before_stim' or entry_name.startswith('Step') and entry_name.endswith('ms') and entry1['feature'] == 'AP_count_after_stim':\n",
    "                entry1['val'][1] = 0.01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AHP depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in json_file_feature.values():\n",
    "    for entry_name, entry in output.items():\n",
    "        for entry1 in entry['soma.v']:\n",
    "            if entry1['feature'].startswith('AHP_depth'):\n",
    "                entry1['weight'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_template = {\n",
    "    \"Pulse\": {\n",
    "        \"type\": \"StepProtocol\", \n",
    "        \"stimuli\": {\n",
    "            \"step\": {\"delay\": 5000, \"amp\":-1.0, \"duration\": 0.5, \"totduration\": 8000}\n",
    "        }\n",
    "    },\n",
    "    \"Step_2000ms\": {\n",
    "        \"type\": \"StepProtocol\", \n",
    "        \"stimuli\": {\n",
    "            \"step\": {\"delay\": 5000, \"amp\":-0.01, \"duration\": 100, \"totduration\": 8000}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_json_prot(cur_key, stim_amp, stim_dur, stim_hold, prefix='', delay=5000, tpad=1000.0):\n",
    "    tdur = stim_dur + delay + tpad\n",
    "    return {(prefix+\"Step%i_%ims\")%(cur_key, stim_dur): {\n",
    "        \"type\": \"StepProtocol\", \n",
    "        \"stimuli\": {\n",
    "            \"step\": {\"delay\": delay, \"amp\": round(stim_amp/1000.0, 3), \"duration\": stim_dur, \"totduration\": tdur},\n",
    "            \"holding\": {\"amp\": round(stim_hold/1000.0,3), \"delay\": 0, \"duration\": tdur, \"totduration\": tdur}\n",
    "        }}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_protocol_output(data, efeature_names, cur_key, prefix='', stim_dur_flag=True, stim_amp_flag=True):        \n",
    "    json_file_output = {}\n",
    "    for k, g in data.groupby(['state']):\n",
    "        json_file_output[k] = {}\n",
    "        \n",
    "        hold = g['bias current'].mean()\n",
    "        \n",
    "        output = {}\n",
    "        for kk, gg in g.groupby([cur_key, 'stim dur']):\n",
    "            output.update(row_to_json_prot(kk[0], gg['step current'].mean(), kk[1], hold, prefix=prefix))\n",
    "        json_file_output[k].update(output)\n",
    "    return json_file_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output = get_json_protocol_output(data_fi_selection, efeatures['fi'], 'step current norm')\n",
    "\n",
    "for k in json_file_protocol:\n",
    "    json_file_protocol[k].update(output[k])\n",
    "    \n",
    "    \n",
    "output = get_json_protocol_output(data_sag_selection, efeatures['rmih'], 'step current norm', prefix='Sag')\n",
    "\n",
    "for k in json_file_protocol:\n",
    "    json_file_protocol[k].update(output[k])\n",
    "    \n",
    "    \n",
    "for k in json_file_protocol:\n",
    "    json_file_protocol[k].update(copy.deepcopy(protocol_template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Step100_2000ms': {'type': 'StepProtocol', 'stimuli': {'step': {'delay': 5000, 'amp': 0.165, 'duration': 2000.0, 'totduration': 8000.0}, 'holding': {'amp': 0.089, 'delay': 0, 'duration': 8000.0, 'totduration': 8000.0}}}, 'Step120_2000ms': {'type': 'StepProtocol', 'stimuli': {'step': {'delay': 5000, 'amp': 0.198, 'duration': 2000.0, 'totduration': 8000.0}, 'holding': {'amp': 0.089, 'delay': 0, 'duration': 8000.0, 'totduration': 8000.0}}}, 'Step140_2000ms': {'type': 'StepProtocol', 'stimuli': {'step': {'delay': 5000, 'amp': 0.231, 'duration': 2000.0, 'totduration': 8000.0}, 'holding': {'amp': 0.089, 'delay': 0, 'duration': 8000.0, 'totduration': 8000.0}}}, 'SagStep200_2000ms': {'type': 'StepProtocol', 'stimuli': {'step': {'delay': 5000, 'amp': -0.17, 'duration': 2000.0, 'totduration': 8000.0}, 'holding': {'amp': 0.006, 'delay': 0, 'duration': 8000.0, 'totduration': 8000.0}}}, 'Pulse': {'type': 'StepProtocol', 'stimuli': {'step': {'delay': 5000, 'amp': -1.0, 'duration': 0.5, 'totduration': 8000}}}, 'Step_2000ms': {'type': 'StepProtocol', 'stimuli': {'step': {'delay': 5000, 'amp': -0.01, 'duration': 100, 'totduration': 8000}}}}\n",
      "{'Step100_2000ms': {'type': 'StepProtocol', 'stimuli': {'step': {'delay': 5000, 'amp': 0.069, 'duration': 2000.0, 'totduration': 8000.0}, 'holding': {'amp': 0.052, 'delay': 0, 'duration': 8000.0, 'totduration': 8000.0}}}, 'Step200_2000ms': {'type': 'StepProtocol', 'stimuli': {'step': {'delay': 5000, 'amp': 0.138, 'duration': 2000.0, 'totduration': 8000.0}, 'holding': {'amp': 0.052, 'delay': 0, 'duration': 8000.0, 'totduration': 8000.0}}}, 'Step300_2000ms': {'type': 'StepProtocol', 'stimuli': {'step': {'delay': 5000, 'amp': 0.207, 'duration': 2000.0, 'totduration': 8000.0}, 'holding': {'amp': 0.052, 'delay': 0, 'duration': 8000.0, 'totduration': 8000.0}}}, 'SagStep200_2000ms': {'type': 'StepProtocol', 'stimuli': {'step': {'delay': 5000, 'amp': -0.127, 'duration': 2000.0, 'totduration': 8000.0}, 'holding': {'amp': 0.0, 'delay': 0, 'duration': 8000.0, 'totduration': 8000.0}}}, 'Pulse': {'type': 'StepProtocol', 'stimuli': {'step': {'delay': 5000, 'amp': -1.0, 'duration': 0.5, 'totduration': 8000}}}, 'Step_2000ms': {'type': 'StepProtocol', 'stimuli': {'step': {'delay': 5000, 'amp': -0.01, 'duration': 100, 'totduration': 8000}}}}\n"
     ]
    }
   ],
   "source": [
    "for k in json_file_feature:\n",
    "    s = json.dumps(json_file_feature[k], indent=4)\n",
    "    for i in range(20, 12, -4):\n",
    "        s = s.replace('\\n' + (' ' * i), ' ')\n",
    "    for i in range(20, 8, -4):\n",
    "        s = s.replace('\\n' + (' ' * i) + '}', ' }')\n",
    "    with open(\"%s_features.json\"%k, \"w\") as fo:\n",
    "        fo.write(s)\n",
    "        \n",
    "        \n",
    "for k in json_file_protocol:\n",
    "    print (json_file_protocol[k])\n",
    "    s = json.dumps(json_file_protocol[k], indent=4)\n",
    "    for i in range(20, 12, -4):\n",
    "        s = s.replace('\\n' + (' ' * i), ' ')\n",
    "    for i in range(20, 8, -4):\n",
    "        s = s.replace('\\n' + (' ' * i) + '}', ' }')\n",
    "    with open(\"%s_protocols.json\"%k, \"w\") as fo:\n",
    "        fo.write(s)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
